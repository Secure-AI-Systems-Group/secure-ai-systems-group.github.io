<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Required meta tags -->
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

        <!-- Title -->
        <title>
            CS499/599 | AI539 :: F23 :: Trustworthy ML
        </title>

        <!-- SEO -->
        <meta name="author" content="Sanghyun Hong">
        <meta name="description" content="Trustworthy Machine Learning Oregon State University">
        <meta name="keywords" content="sanghyun hong albert trustworthy machine learning oregon state university">

        <!-- Favicon -->
        <link rel="shortcut icon" href="/resources/favicon.ico" type="image/x-icon">

        <!-- Prevent js cache by Chrome -->
        <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
        <meta http-equiv="Pragma" content="no-cache" />
        <meta http-equiv="Expires" content="0" />

        <!-- Bootstrap start -->
        <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Arial:300,400,500,700" />
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

        <!-- CSS -->
        <link rel="stylesheet" type="text/css" href="/css/osu-fonts.css">
        <link rel="stylesheet" type="text/css" href="/css/osu-styles.css">

    </head>
    <body>

        <!-- Content -->
        <div class="container">

            <!-- Title -->
            <h2 class="title">
                <b>CS499/579, AI539 :: F23 :: Trustworthy Machine Learning</b>
            </h2>

            <hr noshade="" size="1">


            <!-- Top navigation bar -->
            <ul class="nav">
                <li class="nav-item">
                    <a class="nav-link" href="index.html"><h5>Home</h5></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" aria-current="page" href="syllabus.html"><h5>Syllabus</h5></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="critiques.html"><h5>Critique, Presentation</h5></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="homework.html"><h5>Homework</h5></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="project.html"><h5>Project</h5></a>
                </li>
                <!--
                <li class="nav-item">
                    <a class="nav-link" href="vs_sanghyun.html"><h5>vs. Sanghyun</h5></a>
                </li> -->
            </ul>

            <hr noshade="" size="1">


            <!-- Textbook & Prerequisite -->
            <div class="container">
                <div class="row">
                    <div class="col-6">
                        <h4>Textbooks</h4>
                        <p>
                            <b>No required textbook.</b> Reading materials will be provided on the course website and/or distributed in class. If you lack the basics in machine learning (or deep learning), the following bibles can be helpful:
                        </p>
        
                        <ul>
                            <li>[FOD'20] Mathematics for Machine Learning <a href="https://mml-book.com/" target="_blank">[PDF]</a> </li>
                            <li>[<span class="tab"></span>B'06] Pattern Recognition and Machine Learning <a href="https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book" target="_blank">[PDF]</a></li>
                            <li>[GBC'16] Deep Learning <a href="http://www.deeplearningbook.org/" target="_blank">[PDF]</a></li>
                        </ul>
                        <br/>
        
                        <h4>Prerequisites</h4>
                        <p>
                            This course requires a basic understanding of ML. Please consider taking <i>CS 434 :: Machine Learning and Data Mining</i> first.
                        </p>
                    </div>
        
                    <div class="col-6">
                        <h4>Grading</h4>
                        <p>
                            Your final grade for this course will be based on the following scheme:
                        </p>
                        <ul>
                            <li><b>30%:</b> Written paper critiques [<a href="critiques.html">Details</a>]</li>
                            <li><b>10%:</b> In-class paper presentation [<a href="critiques.html">Details</a>]</li>
                            <li><b>20%:</b> Homeworks (HW 1-4) [<a href="homework.html">Details</a>]</li>
                            <li><b>30%:</b> Group project [<a href="project.html">Details</a>]</li>
                            <li><b>10%:</b> Final exam</li>
                            <br/>
                            <li><b style="color: #D73F09">[Bonus] ~20%:</b> Extra point opportunities</li>
                                <ul>
                                    <li><b style="color: #D73F09">+5%:</b> Outstanding project work</li>
                                    <li><b style="color: #D73F09">+5%:</b> Writing a critique with ChatGPT</li>
                                    <li><b style="color: #D73F09">+10%:</b> Submitting the final report to workshops</li>
                                    <!-- <li><b style="color: #D73F09">+10%:</b> Evading Sanghyun's backdoor detection</li> -->
                                </ul>
                        </ul>
                    </div>
                </div>
            </div>

            <hr noshade="" size="1">


            <!-- Latest announcements -->
            <div class="container" style="background-color: #FAE0D6; border: 0.5px solid #D73F09;">
                <h4 style="margin-top: 10px;">Latest Announcements 
                    <span style="font-size: large;">[<a href="announce.html">Full List</a>]</span></h4>
                <ul>
                    <li><b style="color: #D73F09">[Active]</b> <b>11/09/23:</b> No lecture; the recording will be offered by Sanghyun..</li>
                    <li><b style="color: #D73F09">[Active]</b> <b>11/02/23:</b> Class switching to online and the rest lectures will be on Zoom.</li>
                    <li><b style="color: #D73F09">[Active]</b> <b>10/30/23:</b> HW2 deadline extension; You can submit by the 7th of Nov.</li>
                    <li><b>10/17/23:</b> No class on the 17th; Sanghyun will upload the recording.</li>
                    <li><b>09/28/23:</b> This class will be offered online from the first week of Nov.</li>
                    <li><b>09/28/23:</b> Welcome to CS499/579 | AI539 Trustworthy ML!</li>
                </ul>
            </div>

            <hr noshade="" size="1">


            <!-- Schedule -->
            <div class="container">
                <h4>Schedule</h4>
                <b style="color: #D73F09">[Note]</b><br/>
                &nbsp; <b style="color: #D73F09">- The class will be offered online from the first week of Nov.</b><br/>
                &nbsp; <b style="color: #D73F09">- This is a tentative schedule; subject to change depending on the progress.</b>

                <table class="table">

                    <!-- Header -->
                    <thead><tr style="background-color: #D73F09">
                        <th scope="col" style="text-align:center; color: white"><b>Date</b></th>
                        <th scope="col" style="text-align:center; color: white"><b>Topics</b></th>
                        <th scope="col" style="text-align:center; color: white"><b>Notice</b></th>
                        <th scope="col" style="text-align:center; color: white"><b>Readings</b></th>
                    </tr></thead>


                    <!-- Body of the course schedule -->
                    <tbody>
                    <tr style="background-color: #FFB500">
                        <td colspan=4 style="text-align:center"><b>Part I: Overview and Motivation</b></td></tr>
                    <tr>
                        <td><b>Thu.<br/>09/28</b></td>
                        <td>Introduction<br/>[<a href="slides/01_Introduction.pdf" target="_blank">Slides</a>]</td>
                        <td><b style="color: #000000">[<a href="homework.html">HW 1</a> Out]</b></td>
                        <td>
                            (Classic) <a href="https://ieeexplore.ieee.org/document/8406613" target="_blank">SoK: Security and Privacy in Machine Learning</a><br/>
                        </td>
                    </tr>

                    <!-- Adversarial examples... -->
                    <tr style="background-color: #FFB500">
                        <td colspan=4 style="text-align:center"><b>Part II: Adversarial Examples</b></td></tr>
                    <tr>
                        <td><b>Tue.<br/>10/03</b></td>
                        <td>Preliminaries<br/>[<a href="slides/02_Advex_preliminaries.pdf" target="_blank">Slides</a>]</td>
                        <td></td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1412.6572" target="_blank">Explaining and Harnessing Adversarial Examples</a><br/>
                            (Classic) <a href="https://arxiv.org/abs/1608.04644" target="_blank">Towards Evaluating the Robustness of Neural Networks</a><br/>
                            (Classic) <a href="https://arxiv.org/abs/1706.06083" target="_blank">Towards Deep Learning Models Resistant to Adversarial Attacks</a>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>10/05</b></td>
                        <td>Attacks<br/>[<a href="slides/03_Advex_attacks.pdf" target="_blank">Slides</a>]</td>
                        <td></td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1611.02770" target="_blank">Delving into Transferable Adversarial Examples and Black-box Attacks</a><br/>
                            (Classic) <a href="https://arxiv.org/abs/1704.03453" target="_blank">The Space of Transferable Adversarial Examples</a><br/>
                            (Recent) <a href="https://www.usenix.org/conference/usenixsecurity19/presentation/demontis" target="_blank">Why Do Adversarial Attacks Transfer?</a>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Tue.<br/>10/10</b></td>
                        <td>Attacks<br/>[<a href="slides/04_Advex_attacks.pdf" target="_blank">Slides</a>]</td>
                        <td>
                            [<a href="https://docs.google.com/spreadsheets/d/17bOEn9vE5uOfq9csouk31CnF4mBSu-Yg8ZgpnRFZKTw/edit?usp=sharing" target="_blank">Team-up!</a>]
                        </td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1807.07978" target="_blank">Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors</a><br/>
                            (Recent) <a href="https://arxiv.org/abs/1906.06919" target="_blank">Improving Black-box Adversarial Attacks with a Transfer-based Prior
                            </a>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>10/12</b></td>
                        <td>Attacks<br/>[<a href="slides/05_Advex_practicality.pdf" target="_blank">Slides</a>]</td>
                        <td>
                            <b style="color: #000000">[<a href="homework.html">HW 1</a> Due]</b><br/>
                            <b style="color: #000000">[<a href="homework.html">HW 2</a> Out]</b>
                        </td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1607.02533" target="_blank">Adversarial Examples in the Physical World</a><br/>
                            (Recent) <a href="https://www.usenix.org/conference/usenixsecurity21/presentation/sato" target="_blank">Dirty Road Can Attack: ...</a>(cropped the title due to the space limit)<br/>
                            (Recent) <a href="https://llm-attacks.org/" target="_blank">Universal and Transferable Adversarial Attacks on Aligned Language Models</a>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Tue.<br/>10/17</b></td>
                        <td>Defenses<br/>[<a href="slides/06_Advex_defense.pdf" target="_blank">Slides</a>]</td>
                        <td>
                            <b style="color: #000000">[<a href="https://canvas.oregonstate.edu/courses/1942687/discussion_topics/10449955">Recording</a>]</b>
                        </td>
                        <td>
                            <b>[No class]</b> Sanghyun will upload the recording for this class.<br/>
                            (Classic) <a href="https://arxiv.org/abs/1704.01155" target="_blank">Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks</a><br/>
                            (Classic) <b>[Revisit'ed]</b> <a href="https://arxiv.org/abs/1706.06083" target="_blank">Towards Deep Learning Models Resistant to Adversarial Attacks</a>
                        </td>
                    </tr>

                    <!-- :: Group Projects :: -->
                    <tr style="background-color: #F7A162">
                        <td><b>Thu.<br/>10/19</b></td>
                        <td><b>Group Project</b></td>
                        <td></td>
                        <td><b>Checkpoint Presentation 1</b></td>
                    </tr>

                    <tr>
                        <td><b>Tue.<br/>10/24</b></td>
                        <td>(Certified) Defenses<br/>[<a href="slides/07_Advex_certified_defense.pdf" target="_blank">Slides</a>]</td>
                        <td></td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1902.02918" target="_blank">Certified Adversarial Robustness via Randomized Smoothing</a><br/>
                            (Recent) <a href="https://arxiv.org/abs/2206.10550" target="_blank">(Certified!!) Adversarial Robustness for Free!</a>
                        </td>
                    </tr>

                    <!-- Data poisonig attacks... -->
                    <tr style="background-color: #FFB500">
                        <td colspan=4 style="text-align:center"><b>Part III: Data Poisoning</b></td></tr>

                    <tr>
                        <td><b>Thu.<br/>10/26</b></td>
                        <td>Preliminaries<br/>[<a href="slides/08_Posioning_Preliminaries.pdf" target="_blank">Slides</a>]</td>
                        <td></td>
                        <td>
                            (Recent) <a href="https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-poisoning" target="_blank">Poisoning the Unlabeled Dataset of Semi-Supervised Learning</a><br/>
                            (Recent) <a href="https://www.usenix.org/conference/usenixsecurity21/presentation/schuster" target="_blank">
                                You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion</a><br/>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Tue.<br/>10/31</b></td>
                        <td>Attacks<br/>[<a href="slides/09_Posioning_Indiscriminate.pdf" target="_blank">Slides</a>]</td>
                        <td>
                            <b style="color: #000000">[<a href="homework.html">HW 3</a> Out]</b>
                        </td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1206.6389" target="_blank">Poisoning Attacks against Support Vector Machines</a><br/>
                            (Classic) <a href="https://arxiv.org/abs/1804.00308" target="_blank">Manipulating Machine Learning: Poisoning Attacks and Countermeasures...</a>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>11/02</b></td>
                        <td>Attacks<br/>[<a href="slides/10_Poisoning_targeted.pdf" target="_blank">Slides</a>]</td>
                        <td></td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1804.00792" target="_blank">Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks</a><br/>
                            (Classic) <a href="https://arxiv.org/abs/2004.00225" target="_blank">MetaPoison: Practical General-purpose Clean-label Data Poisoning</a><br/>
                        </td>
                    </tr>

                    <tr style="background-color: #000000">
                        <td colspan=4 style="color: #FFFFFF; text-align:center"><b>The rest lectures will be offered online (Zoom)</b></td></tr>

                    <tr style="background-color: #F7A162">
                        <td><b>Tue.<br/>11/07</b></td>
                        <td><b>Group Project</b></td>
                        <td>
                            <b style="color: #000000">[<a href="homework.html">HW 2</a> Due]</b>
                        </td>
                        <td><b>Checkpoint Presentation 2</b></td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>11/09</b></td>
                        <td>Defenses<br/>[<a href="slides/11_Posioning_defenses.pdf" target="_blank">Slides</a>]</td>
                        <td>
                            <b style="color: #000000">[<a href="https://canvas.oregonstate.edu/courses/1942687/discussion_topics/10477809">Recording</a>]</b>
                        </td>
                        </td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1706.03691" target="_blank">Certified Defenses for Data Poisoning Attacks</a><br/>
                            (Classic) <a href="https://arxiv.org/abs/1903.09860" target="_blank">Data Poisoning against Differentially-Private Learners: Attacks and Defenses</a><br/>
                        </td>
                    </tr>

                    <!-- Privacy attacks -->
                    <tr style="background-color: #FFB500">
                        <td colspan=4 style="text-align:center"><b>Part IV: Privacy</b></td></tr>
                    <tr>
                        <td><b>Tue.<br/>11/14</b></td>
                        <td>Preliminaries<br/>[<a href="slides/12_Privacy_preliminaries.pdf" target="_blank">Slides</a>]</td>
                        <td>
                            <b>[<a href="homework.html">HW 4</a> Out]</b>
                        </td>
                        <td>
                            (Classic) <a href="https://privacytools.seas.harvard.edu/files/privacytools/files/pdf_02.pdf" target="_blank">Exposed! A Survey of Attacks on Private Data</a><br/>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>11/16</b></td>
                        <td>Attack<br/>[<a href="slides/13_Privacy_MIA.pdf" target="_blank">Slides</a>]</td>
                        <td>
                            <b style="color: #000000">[<a href="homework.html">HW 3</a> Due]</b>
                        </td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1610.05820" target="_blank">Membership Inference Attacks against Machine Learning Models</a><br/>
                            (Classic) <a href="https://arxiv.org/abs/1709.01604" target="_blank">Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting</a><br/>
                            (Recent) <a href="https://arxiv.org/abs/2112.03570" target="_blank">Membership Inference Attacks From First Principles</a>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>11/21</b></td>
                        <td>Attack<br/>[<a href="" target="_blank">Slides</a>]</td>
                        <td></td>
                        <td>
                            (Classic) <a href="https://dl.acm.org/doi/10.1145/2810103.2813677" target="_blank">Model Inversion that Exploit Confidence Information and Basic Countermeasures</a><br/>
                            (Recent) <a href="https://arxiv.org/abs/1802.08232" target="_blank">The Secret Sharer: Evaluating and Testing Unintended Memorization in NNs</a><br/>
                            (Recent) <a href="https://arxiv.org/abs/2012.07805" target="_blank">Extracting Training Data from Large Language Models</a>
                        </td>
                    </tr>
                    
                    <tr style="background-color: #B8DDE1">
                        <td><b>Tue.<br/>11/23</b></td>
                        <td></td>
                        <td>
                            <b>[No lecture]</b><br/>
                        </td>
                        <td>
                            <b style="color: #D73F09">Thanksgiving Break.</b>
                        </td>
                    </tr>
                    
                    <tr>
                        <td><b>Tue.<br/>11/28</b></td>
                        <td>Attack<br/>[<a href="" target="_blank">Slides</a>]</td>
                        <td></td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1609.02943" target="_blank">Stealing Machine Learning Models via Prediction APIs</a><br/>
                            (Recent) <a href="https://arxiv.org/abs/1909.01838" target="_blank">High Accuracy and High Fidelity Extraction of Neural Networks</a>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>11/30</b></td>
                        <td>(Certified) Defense<br/>[<a href="" target="_blank">Slides</a>]</td>
                        <td>
                            <b style="color: #000000">[<a href="homework.html">HW 4</a> Due]</b>
                        </td>
                        <td>
                            (Classic) <a href="https://arxiv.org/abs/1607.00133" target="_blank">Deep Learning with Differential Privacy</a><br/>
                            (Recent) <a href="https://arxiv.org/abs/1902.08874" target="_blank">Evaluating Differentially Private Machine Learning in Practice</a><br/>
                            (Recent) <a href="https://deepmind.com/research/publications/2022/Red-Teaming-Language-Models-with-Language-Models" target="_blank">Red Teaming LMs with LMs</a>
                        </td>
                    </tr>

                    <tr style="background-color: #B8DDE1">
                        <td><b>Tue.<br/>12/05</b></td>
                        <td></td>
                        <td>
                            <b>[No lecture]</b><br/>
                        </td>
                        <td>
                            <b style="color: #D73F09">Final Presentation Prep.</b>
                        </td>
                    </tr>

                    <tr style="background-color: #F7A162">
                        <td><b>Thu.<br/>12/07</b></td>
                        <td><b>Group Project</b></td>
                        <td></td>
                        <td><b>Final Presentations (Showcases)</b></td>
                    </tr>

                    <!-- Finals week -->
                    <tr style="background-color: #FFB500">
                        <td colspan=4 style="text-align:center"><b>Finals Week (12/11 - 12/05)</b></td>
                    </tr>

                    <tr>
                        <td><b>Tue.<br/>12/12</b></td>
                        <td><b>-</b></td>
                        <td>
                            <b style="color: #000000">[No Lecture]<br/>
                            [<a href="" target="_blank">Final Exam</a>]<br/></b>
                        </td>
                        <td>
                            <b>Final Exam & Submit your final project report.</b>
                        </td>
                    </tr>

                    <tr>
                        <td><b>Thu.<br/>12/14</b></td>
                        <td><b>-</b></td>
                        <td>
                            <b style="color: #000000">[No Lecture]</b>
                        </td>
                        <td><b>Late submissions for HW 1-4.</b></td>
                    </tr>

                    </tbody>

                </table>
            </div>


            <!-- Footer -->
            <hr noshade="" size="1">
            <footer class="footer" style="margin-bottom: 24px;">
                <div class="container text-center">
                  <span class="text-muted">© Sanghyun Hong: 2022-Present.</span>
                </div>
            </footer>

        </div>

        <!-- Optional Javascript -->
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

    </body>
</html>
